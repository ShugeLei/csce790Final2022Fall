{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkoGLH_Tj5wn"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ORj09gnrj5wp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6hghKPxj5w0"
      },
      "source": [
        "## Model Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NnT0sZIwj5wu"
      },
      "outputs": [],
      "source": [
        "### SETTINGS\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Architecture\n",
        "NUM_FEATURES = 28*28\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# Other\n",
        "DEVICE = \"cuda:0\"\n",
        "GRAYSCALE = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYaKcZKtWbbK"
      },
      "source": [
        "### MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_zEHQBMWbbK",
        "outputId": "cb6fd2fa-d3f5-4dc9-c877-3d5f3626a12a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
            "Image label dimensions: torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "### MNIST DATASET\n",
        "\n",
        "train_dataset = datasets.MNIST(root='data', \n",
        "                               train=True, \n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='data', \n",
        "                              train=False, \n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=BATCH_SIZE, \n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=BATCH_SIZE, \n",
        "                         shuffle=False)\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEELkashWbbL",
        "outputId": "8489bf6c-eb0e-4b9f-ef42-02eddf1d5f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
            "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(DEVICE)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "for epoch in range(2):\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        \n",
        "        print('Epoch:', epoch+1, end='')\n",
        "        print(' | Batch index:', batch_idx, end='')\n",
        "        print(' | Batch size:', y.size()[0])\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zdsjeh_iWbbL"
      },
      "outputs": [],
      "source": [
        "### MODEL\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes, grayscale):\n",
        "        self.inplanes = 64\n",
        "        if grayscale:\n",
        "            in_dim = 1\n",
        "        else:\n",
        "            in_dim = 3\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, (2. / n)**.5)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        # because MNIST is already 1x1 here:\n",
        "        # disable avg pooling\n",
        "        #x = self.avgpool(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.fc(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas\n",
        "\n",
        "def resnet18(num_classes):\n",
        "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
        "    model = ResNet(block=BasicBlock, \n",
        "                   layers=[2, 2, 2, 2],\n",
        "                   num_classes=NUM_CLASSES,\n",
        "                   grayscale=GRAYSCALE)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_lza9t_uj5w1"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = resnet18(NUM_CLASSES)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAodboScj5w6"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzh3ROmRj5w7",
        "outputId": "ed841db7-84dd-4b8c-b71d-da503a1a47dd",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/010 | Batch 0000/0469 | Cost: 2.6379\n",
            "Epoch: 001/010 | Batch 0050/0469 | Cost: 0.1660\n",
            "Epoch: 001/010 | Batch 0100/0469 | Cost: 0.0784\n",
            "Epoch: 001/010 | Batch 0150/0469 | Cost: 0.0623\n",
            "Epoch: 001/010 | Batch 0200/0469 | Cost: 0.0953\n",
            "Epoch: 001/010 | Batch 0250/0469 | Cost: 0.1699\n",
            "Epoch: 001/010 | Batch 0300/0469 | Cost: 0.0402\n",
            "Epoch: 001/010 | Batch 0350/0469 | Cost: 0.1796\n",
            "Epoch: 001/010 | Batch 0400/0469 | Cost: 0.1229\n",
            "Epoch: 001/010 | Batch 0450/0469 | Cost: 0.0295\n",
            "Epoch: 001/010 | Train: 94.390%\n",
            "Time elapsed: 0.49 min\n",
            "Epoch: 002/010 | Batch 0000/0469 | Cost: 0.1506\n",
            "Epoch: 002/010 | Batch 0050/0469 | Cost: 0.0463\n",
            "Epoch: 002/010 | Batch 0100/0469 | Cost: 0.0489\n",
            "Epoch: 002/010 | Batch 0150/0469 | Cost: 0.0236\n",
            "Epoch: 002/010 | Batch 0200/0469 | Cost: 0.0574\n",
            "Epoch: 002/010 | Batch 0250/0469 | Cost: 0.0218\n",
            "Epoch: 002/010 | Batch 0300/0469 | Cost: 0.0197\n",
            "Epoch: 002/010 | Batch 0350/0469 | Cost: 0.0934\n",
            "Epoch: 002/010 | Batch 0400/0469 | Cost: 0.0243\n",
            "Epoch: 002/010 | Batch 0450/0469 | Cost: 0.0329\n",
            "Epoch: 002/010 | Train: 98.252%\n",
            "Time elapsed: 0.84 min\n",
            "Epoch: 003/010 | Batch 0000/0469 | Cost: 0.0213\n",
            "Epoch: 003/010 | Batch 0050/0469 | Cost: 0.0780\n",
            "Epoch: 003/010 | Batch 0100/0469 | Cost: 0.0423\n",
            "Epoch: 003/010 | Batch 0150/0469 | Cost: 0.0206\n",
            "Epoch: 003/010 | Batch 0200/0469 | Cost: 0.1219\n",
            "Epoch: 003/010 | Batch 0250/0469 | Cost: 0.0285\n",
            "Epoch: 003/010 | Batch 0300/0469 | Cost: 0.0163\n",
            "Epoch: 003/010 | Batch 0350/0469 | Cost: 0.0599\n",
            "Epoch: 003/010 | Batch 0400/0469 | Cost: 0.0190\n",
            "Epoch: 003/010 | Batch 0450/0469 | Cost: 0.0176\n",
            "Epoch: 003/010 | Train: 99.293%\n",
            "Time elapsed: 1.19 min\n",
            "Epoch: 004/010 | Batch 0000/0469 | Cost: 0.0535\n",
            "Epoch: 004/010 | Batch 0050/0469 | Cost: 0.0134\n",
            "Epoch: 004/010 | Batch 0100/0469 | Cost: 0.0061\n",
            "Epoch: 004/010 | Batch 0150/0469 | Cost: 0.0417\n",
            "Epoch: 004/010 | Batch 0200/0469 | Cost: 0.0310\n",
            "Epoch: 004/010 | Batch 0250/0469 | Cost: 0.0723\n",
            "Epoch: 004/010 | Batch 0300/0469 | Cost: 0.1316\n",
            "Epoch: 004/010 | Batch 0350/0469 | Cost: 0.0079\n",
            "Epoch: 004/010 | Batch 0400/0469 | Cost: 0.0709\n",
            "Epoch: 004/010 | Batch 0450/0469 | Cost: 0.0057\n",
            "Epoch: 004/010 | Train: 99.342%\n",
            "Time elapsed: 1.54 min\n",
            "Epoch: 005/010 | Batch 0000/0469 | Cost: 0.0246\n",
            "Epoch: 005/010 | Batch 0050/0469 | Cost: 0.0134\n",
            "Epoch: 005/010 | Batch 0100/0469 | Cost: 0.0080\n",
            "Epoch: 005/010 | Batch 0150/0469 | Cost: 0.0245\n",
            "Epoch: 005/010 | Batch 0200/0469 | Cost: 0.0237\n",
            "Epoch: 005/010 | Batch 0250/0469 | Cost: 0.0374\n",
            "Epoch: 005/010 | Batch 0300/0469 | Cost: 0.0240\n",
            "Epoch: 005/010 | Batch 0350/0469 | Cost: 0.0295\n",
            "Epoch: 005/010 | Batch 0400/0469 | Cost: 0.0046\n",
            "Epoch: 005/010 | Batch 0450/0469 | Cost: 0.0562\n",
            "Epoch: 005/010 | Train: 99.403%\n",
            "Time elapsed: 1.89 min\n",
            "Epoch: 006/010 | Batch 0000/0469 | Cost: 0.0038\n",
            "Epoch: 006/010 | Batch 0050/0469 | Cost: 0.0239\n",
            "Epoch: 006/010 | Batch 0100/0469 | Cost: 0.0058\n",
            "Epoch: 006/010 | Batch 0150/0469 | Cost: 0.0829\n",
            "Epoch: 006/010 | Batch 0200/0469 | Cost: 0.0385\n",
            "Epoch: 006/010 | Batch 0250/0469 | Cost: 0.0089\n",
            "Epoch: 006/010 | Batch 0300/0469 | Cost: 0.0029\n",
            "Epoch: 006/010 | Batch 0350/0469 | Cost: 0.0113\n",
            "Epoch: 006/010 | Batch 0400/0469 | Cost: 0.0437\n",
            "Epoch: 006/010 | Batch 0450/0469 | Cost: 0.0141\n",
            "Epoch: 006/010 | Train: 98.798%\n",
            "Time elapsed: 2.25 min\n",
            "Epoch: 007/010 | Batch 0000/0469 | Cost: 0.0424\n",
            "Epoch: 007/010 | Batch 0050/0469 | Cost: 0.0039\n",
            "Epoch: 007/010 | Batch 0100/0469 | Cost: 0.0068\n",
            "Epoch: 007/010 | Batch 0150/0469 | Cost: 0.0030\n",
            "Epoch: 007/010 | Batch 0200/0469 | Cost: 0.0228\n",
            "Epoch: 007/010 | Batch 0250/0469 | Cost: 0.0429\n",
            "Epoch: 007/010 | Batch 0300/0469 | Cost: 0.0092\n",
            "Epoch: 007/010 | Batch 0350/0469 | Cost: 0.0072\n",
            "Epoch: 007/010 | Batch 0400/0469 | Cost: 0.0023\n",
            "Epoch: 007/010 | Batch 0450/0469 | Cost: 0.0477\n",
            "Epoch: 007/010 | Train: 99.597%\n",
            "Time elapsed: 2.60 min\n",
            "Epoch: 008/010 | Batch 0000/0469 | Cost: 0.0013\n",
            "Epoch: 008/010 | Batch 0050/0469 | Cost: 0.0024\n",
            "Epoch: 008/010 | Batch 0100/0469 | Cost: 0.0342\n",
            "Epoch: 008/010 | Batch 0150/0469 | Cost: 0.0007\n",
            "Epoch: 008/010 | Batch 0200/0469 | Cost: 0.0021\n",
            "Epoch: 008/010 | Batch 0250/0469 | Cost: 0.0201\n",
            "Epoch: 008/010 | Batch 0300/0469 | Cost: 0.1417\n",
            "Epoch: 008/010 | Batch 0350/0469 | Cost: 0.0018\n",
            "Epoch: 008/010 | Batch 0400/0469 | Cost: 0.0359\n",
            "Epoch: 008/010 | Batch 0450/0469 | Cost: 0.1048\n",
            "Epoch: 008/010 | Train: 98.875%\n",
            "Time elapsed: 2.95 min\n",
            "Epoch: 009/010 | Batch 0000/0469 | Cost: 0.0056\n",
            "Epoch: 009/010 | Batch 0050/0469 | Cost: 0.0058\n",
            "Epoch: 009/010 | Batch 0100/0469 | Cost: 0.0089\n",
            "Epoch: 009/010 | Batch 0150/0469 | Cost: 0.0737\n",
            "Epoch: 009/010 | Batch 0200/0469 | Cost: 0.0063\n",
            "Epoch: 009/010 | Batch 0250/0469 | Cost: 0.0066\n",
            "Epoch: 009/010 | Batch 0300/0469 | Cost: 0.0569\n",
            "Epoch: 009/010 | Batch 0350/0469 | Cost: 0.0007\n",
            "Epoch: 009/010 | Batch 0400/0469 | Cost: 0.0012\n",
            "Epoch: 009/010 | Batch 0450/0469 | Cost: 0.0026\n",
            "Epoch: 009/010 | Train: 99.478%\n",
            "Time elapsed: 3.29 min\n",
            "Epoch: 010/010 | Batch 0000/0469 | Cost: 0.0061\n",
            "Epoch: 010/010 | Batch 0050/0469 | Cost: 0.0002\n",
            "Epoch: 010/010 | Batch 0100/0469 | Cost: 0.0025\n",
            "Epoch: 010/010 | Batch 0150/0469 | Cost: 0.0974\n",
            "Epoch: 010/010 | Batch 0200/0469 | Cost: 0.0022\n",
            "Epoch: 010/010 | Batch 0250/0469 | Cost: 0.0002\n",
            "Epoch: 010/010 | Batch 0300/0469 | Cost: 0.0544\n",
            "Epoch: 010/010 | Batch 0350/0469 | Cost: 0.0109\n",
            "Epoch: 010/010 | Batch 0400/0469 | Cost: 0.0514\n",
            "Epoch: 010/010 | Batch 0450/0469 | Cost: 0.0066\n",
            "Epoch: 010/010 | Train: 99.810%\n",
            "Time elapsed: 3.64 min\n",
            "Total Training Time: 3.64 min\n"
          ]
        }
      ],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "            \n",
        "        features = features.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        logits, probas = model(features)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "    \n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "        \n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "            \n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        cost.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
        "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
        "                     len(train_loader), cost))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False): # save memory during inference\n",
        "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
        "              epoch+1, NUM_EPOCHS, \n",
        "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
        "        \n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
        "    \n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paaeEQHQj5xC"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzQMWKq5j5xE",
        "outputId": "5679c930-7c8e-455e-829a-df26341f273d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 99.37%\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False): # save memory during inference\n",
        "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "iQbPbWT9WbbN",
        "outputId": "6bbb5ffa-db9b-42de-f58e-c8bc26ea6296"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "for batch_idx, (features, targets) in enumerate(test_loader):\n",
        "\n",
        "    features = features\n",
        "    targets = targets\n",
        "    break\n",
        "    \n",
        "    \n",
        "nhwc_img = np.transpose(features[0], axes=(1, 2, 0))\n",
        "nhw_img = np.squeeze(nhwc_img.numpy(), axis=2)\n",
        "plt.imshow(nhw_img, cmap='Greys');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PklftTx4WbbN",
        "outputId": "31dd240f-e38c-4dc1-fc88-2abe05009c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability 7 100.00%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "logits, probas = model(features.to(device)[0, None])\n",
        "print('Probability 7 %.2f%%' % (probas[0][7]*100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "371px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}